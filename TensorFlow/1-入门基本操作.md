## 入门基本操作

#### 变量的使用

- 在Ptyhon中，变量直接声明使用即可，如`a = 1`
- 但在tf中，没有这么简单，下面的例子展示了tf中声明两个变量并计算乘积的例子
- tensor是TensorFlow中的数据类型，表示程序中传递的数据

```
import tensorflow as tf

# 定义tensor类型变量，以及乘积操作
w = tf.Variable([[1, 2]])
x = tf.Variable([[2], [3]])
y = tf.matmul(w, x)

# 此时只是定义好了w,x,y的tensor类型的模型/框架，w,x,y并没有值
print (w) # ==> <tf.Variable 'Variable_8:0' shape=(1, 2) dtype=int32_ref>
print (x) # ==> <tf.Variable 'Variable_9:0' shape=(2, 1) dtype=int32_ref>
print (y) # ==> Tensor("MatMul_4:0", shape=(1, 1), dtype=int32)

# 定义一个初始化操作给w,x,y赋值
init_op = tf.global_variables_initializer()

# 需要把之前的东西添加到计算图中在session中执行
# session表示一次会话，可理解为计算区域
with tf.Session() as sess:
    sess.run(init_op)
    # 执行完初始化后，可以查看y的值了，但是，y是tensor类型的数据，需要使用eval函数查看值
    print (y.eval()) # ==> [[8]]
```

#### session的使用

- 计算矩阵乘积例子中，使用了with代码块自动创建session，在session中运行计算图，最后关闭session
- 可以不使用with代码块，自己进行session的创建及关闭

```
import tensorflow as tf

# 定义tensor类型变量，以及乘积操作
w = tf.Variable([[1, 2]])
x = tf.Variable([[2], [3]])
y = tf.matmul(w, x)


# 定义一个初始化操作给w,x,y赋值
init_op = tf.global_variables_initializer()

# 手动创建Session对象，不传参数，会话构造器将启动默认图
sess = tf.Session()
sess.run(init_op)
# 值得注意的是，不同于with方式，这里不能使用y.eval()取值，必须通过run对应的op得到相关的值
print (sess.run(y)) # ==> [[8]]

# 任务完成关闭会话
sess.close()
```

- 另外，还可以使用session的交互式

```
import tensorflow as tf

# 进入一个交互式TensorFlow会话(这样可以省略掉with后者其他的session操作，但是貌似仅仅适用于单个session)
sess = tf.InteractiveSession()

x = tf.Variable([1.0, 2.0])
a = tf.constant([3.0, 3.0])

# 使用初始化器initializer op的run方法初始化x
x.initializer.run()

# 增加一个减法subtract op 并执行输出结果
sub = tf.subtract(x,a)
print (sub.eval()) # ==> [-2. -1.]
```

#### 数据的创建

- 在tf中，进行数据的创建操作大体上和np相同
- 浮点数的创建建议使用float32，在CPU,GPU中较为稳定，否则可能出现不易定位的问题
- 为了方便过程中随时run一些op，并打印结果，不在使用固定模式的with代码块创建session，改用session的交互式模式

```
import tensorflow as tf
import numpy as np

sess = tf.InteractiveSession()

# 习惯使用numpy的，可以使用numpy语法初始化数据，再转换成tensor（并不推荐）
npdata = np.zeros((2, 3), dtype=np.int32)
tfdata = tf.convert_to_tensor(npdata)
print(tfdata.eval())# ==> [[0 0 0] [0 0 0]]

# 指定shape创建一个值均为0的矩阵
a = tf.zeros([3, 3], tf.int32)
print (a.eval()) # ==> [[0 0 0] [0 0 0] [0 0 0]]
# 指定shaoe创建一个值均为1的矩阵
b = tf.ones([2, 2], tf.int32)
print (b.eval()) # ==> [[1 1] [1 1]]
# 按照a的shape，创建一个值均为1的矩阵
c = tf.ones_like(a)
print (c.eval()) # ==> [[1 1 1] [1 1 1] [1 1 1]]
# 按照b的shape，创建一个值均为0的矩阵
d = tf.zeros_like(b)
print (d.eval()) # ==> [[0 0] [0 0]]

# 定义tensor的一维常量
cons1 = tf.constant([1, 2, 3])
print (cons1.eval()) # ==> [1 2 3]
# 定义tensor的二维常量
cons2 = tf.constant(-1.0, shape=[2, 2])
print (cons2.eval()) # ==> [[-1. -1.] [-1. -1.]]

# 定义linspace，在先x,y范围内平均取z个数
lins = tf.linspace(1.0, 3.0, 3, name='linspace')
print (lins.eval()) # ==> [ 1.  2.  3.]

# 定义一维列表，数据在x,y范围内，每隔z取一个数值，与numpy的arange相同
rang = tf.range(0, 10, 2)
print (rang.eval()) # ==> [0 2 4 6 8]

# 指定shape创建一个随机矩阵，满足高斯分布，期望-1，方差4
norm = tf.random_normal([2, 3], mean=-1, stddev=4)
print (norm.eval()) # ==> [[  4.51852274 -11.79477978  -9.57752419] [  0.88892114  -2.50875664  -5.82925415]]

# 将原始数据进行洗牌(横向顺序不变，随机调换行位置)
ori = tf.constant([[1, 2], [4, 9], [6, 3]])
shuf = tf.random_shuffle(ori)
print (shuf.eval()) # ==> [[1 2] [6 3] [4 9]]
```

#### 实例：实现一个变量的自加操作

```
import tensorflow as tf

# 创建一个初值为0的变量
state = tf.Variable(0)
# 创建一个相加操作：当前state再加1
new_value = tf.add(state, tf.constant(1))
# 创建一个赋值操作将new_value的返回值赋值给state
update = tf.assign(state, new_value)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print (state.eval())
    for _ in range(3):
        sess.run(update)
        print(state.eval())
```

#### 占位符placeholder

- 使用placeholder占位符，再session中计算图中占位，配合feed_dict使用时再赋值

```
import tensorflow as tf
input1 = tf.placeholder(tf.float32)
input2 = tf.placeholder(tf.float32)
output = tf.multiply(input1, input2)
with tf.Session() as sess:
    print (sess.run([output], feed_dict={input1:[2.], input2:[3.]}))
```

#### 实例MNIST手写数字识别

- 根据官网教程写了一个简单的实现，可以完美奔跑，但每一步原理有待深究，留到后面

```
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data

# 引入数据
mnist = input_data.read_data_sets("MNIST_data", one_hot=True)

# 注册默认session
# sess = tf.InteractiveSession()
# 创建数据输入placeholder
x = tf.placeholder(tf.float32, [None, 784])
# 创建Variable对象
W = tf.Variable(tf.zeros([784,10]))
b = tf.Variable(tf.zeros([10]))
# 使用tf公式
y = tf.nn.softmax(tf.matmul(x, W) + b)

y_ = tf.placeholder(tf.float32, [None,10])
cross_entropy = -tf.reduce_sum(y_ * tf.log(y))

train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)
init = tf.initialize_all_variables()
sess = tf.Session()
sess.run(init)

for i in range(1000):
    batch_xs, batch_ys = mnist.train.next_batch(100)
    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})

correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
print (sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))

```
